{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `torch.Tensor` basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default torch.FloatTensor \n",
    "a = torch.Tensor(5, 5) \n",
    "\n",
    "# one way to generate tensor with specified dtype \n",
    "b = torch.DoubleTensor(5, 5) \n",
    "\n",
    "# generate tensor with values of zero \n",
    "c = torch.zeros([2, 4], dtype=torch.int32)\n",
    " \n",
    "# specified device\n",
    "d = torch.ones([2, 4], dtype=torch.int32, device = \"cuda\")\n",
    "\n",
    "# numpy -> torch.tensor \n",
    "e = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]])) \n",
    "\n",
    "# torch.tensor -> numpy \n",
    "c = c.numpy() \n",
    "\n",
    "# cpu -> gpu \n",
    "e = e.to(\"cuda\")  # AVOID USING torch.cuda() \n",
    "\n",
    "# gpu -> cpu \n",
    "e = e.to(\"cpu\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate `torch.Tensor` shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(100, 200 ,3)\n",
    "print(t.shape)\n",
    "t = t.unsqueeze(0)\n",
    "print(t.shape)\n",
    "t = t.squeeze(0)\n",
    "print(t.shape)\n",
    "t = t.permute((1,0,2))\n",
    "print(t.shape)\n",
    "t = t.flatten()\n",
    "print(t.shape)\n",
    "t = t.reshape(300, -1)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `torch.Tensor` operations (remind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(10, 5)\n",
    "b = torch.Tensor(5, 20)\n",
    "c = torch.Tensor(10, 5)\n",
    "\n",
    "# element-wisely multiply\n",
    "d = a * c\n",
    "print(d.shape)\n",
    "\n",
    "# dot\n",
    "e = a@b\n",
    "print(e.shape)\n",
    "\n",
    "# repeat\n",
    "x = torch.Tensor(3, 4)\n",
    "print(x.repeat(4, 2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `torch.Tensor` requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1.0, 0.0], [-1.0, 1.0]], requires_grad = True)\n",
    "print(x.grad)\n",
    "z = x.pow(2).sum()\n",
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_example(mean = 0, std = 0.2, dim = (32, 32)):\n",
    "    data = np.random.normal(mean, std, size = dim)\n",
    "    label = int(std * 10)\n",
    "    scale = mean\n",
    "    return (data, label, scale)\n",
    "\n",
    "def get_dataset(num = 1000):\n",
    "    all_data = []\n",
    "    all_label = []\n",
    "    all_scale = []\n",
    "    for _ in range(num):\n",
    "        mean = np.random.uniform(low = -1.0, high = 1.0)\n",
    "        std = np.random.uniform(low = 0.1, high = 1.0)\n",
    "        data, label, scale = get_example(mean = mean, std = std)\n",
    "        all_data.append(data)\n",
    "        all_label.append(label)\n",
    "        all_scale.append(scale)\n",
    "    all_data = np.array(all_data)\n",
    "    all_label = np.array(all_label)\n",
    "    all_scale = np.array(all_scale)\n",
    "    return {\"data\":all_data, \"label\":all_label, \"scale\":all_scale}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset): \n",
    "\n",
    "    def __init__(self, data_num): \n",
    "        self.data_num = data_num\n",
    "        self.init_data()\n",
    "\n",
    "    def init_data(self): \n",
    "        dataset = get_dataset(self.data_num)\n",
    "        self.data = dataset[\"data\"].astype(np.float32)\n",
    "        self.label = dataset[\"label\"].astype(np.int)\n",
    "        self.scale = dataset[\"scale\"].astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        return self.data[index], self.label[index], self.scale[index]\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.data_num\n",
    "\n",
    "class GoodModel(nn.Module): \n",
    "    def __init__(self, class_num): \n",
    "        super(GoodModel, self).__init__() \n",
    "        self.flatten = nn.Flatten() \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(32*32, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128), \n",
    "        ) \n",
    "        self.fc1 = nn.Linear(128, class_num)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    " \n",
    "    def forward(self, x): \n",
    "        x = self.flatten(x) \n",
    "        embedding = self.MLP(x) \n",
    "        logits = self.fc1(embedding) \n",
    "        score = self.fc2(embedding) \n",
    "        return logits, score\n",
    "    \n",
    "    def get_embedding(self, x): \n",
    "        x = self.flatten(x) \n",
    "        embedding = self.MLP(x) \n",
    "        return embedding \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = RandomDataset(1000)\n",
    "training_loader = DataLoader(training_dataset, batch_size = 32, shuffle = True)\n",
    "testing_dataset = RandomDataset(1000)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size = 32, shuffle = False)\n",
    "model = GoodModel(10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_fn1 = nn.CrossEntropyLoss()\n",
    "loss_fn2 = nn.L1Loss()\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(100):\n",
    "    loss1_cum = 0\n",
    "    loss2_cum = 0\n",
    "    true = []\n",
    "    pred = []\n",
    "    \n",
    "    model.train()\n",
    "    for data, label, scale in (training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits, score = model(data)\n",
    "        loss1 = loss_fn1(logits, label)\n",
    "        loss2 = loss_fn2(score.flatten(), scale)\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss1_cum += loss1\n",
    "        loss2_cum += loss2\n",
    "\n",
    "        true += list(label)\n",
    "        _, predictions = torch.max(logits, 1)\n",
    "        pred += list(predictions)\n",
    "        \n",
    "    acc = accuracy_score(true, pred)\n",
    "    print(f\"[{e:3d} / epochs] Train Loss: CE {loss1_cum:.3f} L1 {loss2_cum:.3f} || Acc {acc:.3f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss1_cum = 0\n",
    "        loss2_cum = 0\n",
    "        true = []\n",
    "        pred = []\n",
    "        for data, label, scale in (testing_loader): \n",
    "            logits, score = model(data)\n",
    "            loss1 = loss_fn1(logits, label)\n",
    "            loss2 = loss_fn2(score.flatten(), scale)\n",
    "            loss1_cum += loss1\n",
    "            loss2_cum += loss2\n",
    "\n",
    "            true += list(label)\n",
    "            _, predictions = torch.max(logits, 1)\n",
    "            pred += list(predictions)\n",
    "\n",
    "        acc = accuracy_score(true, pred)\n",
    "        print(f\"[{e:3d} / epochs] Test Loss: CE {loss1_cum:.3f} L1 {loss2_cum:.3f} || Acc {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
